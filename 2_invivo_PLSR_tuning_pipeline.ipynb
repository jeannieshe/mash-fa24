{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3165e22e-fabc-456c-84fa-3868df39e7d5",
   "metadata": {},
   "source": [
    "# Tuning PLSR models and testing them against external datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce18ae8-1d47-430a-86da-a5d303056136",
   "metadata": {},
   "source": [
    "## Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63011544-da6c-4c80-8db6-3262ec033cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up\n",
    "# imports\n",
    "import pyreadr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from scipy.stats import pearsonr\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# calculate the mean of the pearson coefficients of multiple variables\n",
    "def pair_pearsonr(x, y, axis=0): # this will allow us to take the pearson coefficient across two variables\n",
    "    mx = np.mean(x, axis=axis, keepdims=True)\n",
    "    my = np.mean(y, axis=axis, keepdims=True)\n",
    "    xm, ym = x-mx, y-my\n",
    "    r_num = np.add.reduce(xm * ym, axis=axis)\n",
    "    r_den = np.sqrt((xm*xm).sum(axis=axis) * (ym*ym).sum(axis=axis))\n",
    "    r = r_num / r_den\n",
    "    return r\n",
    "\n",
    "# plotting setup\n",
    "# Use LaTeX for graphs' text\n",
    "plt.rc('text', usetex=True)\n",
    "# Use the serif font\n",
    "plt.rc('font', family='serif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf087ceb-da8d-4ec2-ad2c-06e73f27f0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data, access pandas df via key \"None\"\n",
    "X_Govaere = pyreadr.read_r(\"datasets/X_Govaere.rds\")[None]\n",
    "X_Hoang = pyreadr.read_r(\"datasets/X_Hoang.rds\")[None]\n",
    "X_Pantano = pyreadr.read_r(\"datasets/X_Pantano.rds\")[None]\n",
    "\n",
    "# actual, clinical results\n",
    "Y_Govaere = pyreadr.read_r(\"datasets/Y_Govaere.rds\")[None]\n",
    "Y_Hoang = pyreadr.read_r(\"datasets/Y_Hoang.rds\")[None]\n",
    "Y_Pantano = pyreadr.read_r(\"datasets/Y_Pantano.rds\")[None]\n",
    "\n",
    "# viper metric, predicted results\n",
    "Y_viper_Govaere = pyreadr.read_r(\"datasets/viper_X_Govaere.rds\")[None]\n",
    "Y_viper_Hoang = pyreadr.read_r(\"datasets/viper_X_Hoang.rds\")[None]\n",
    "Y_viper_Pantano = pyreadr.read_r(\"datasets/viper_X_Pantano.rds\")[None]\n",
    "\n",
    "all_results = pd.read_csv(\"datasets/PLSR_pearson_coefficients.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2a14b199-ff9a-4d87-95ef-ff88cfa80fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique NAS scores and their corresponding frequency:\n",
      "['(0.0, 32)', '(1.0, 12)', '(2.0, 9)', '(3.0, 11)', '(4.0, 13)', '(5.0, 18)', '(6.0, 12)', '(7.0, 9)']\n",
      "Unique Fibrosis scores and their corresponding frequency:\n",
      "['(0.0, 57)', '(1.0, 25)', '(2.0, 25)', '(3.0, 5)', '(4.0, 4)']\n"
     ]
    }
   ],
   "source": [
    "# setup tuning procedure\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=5)\n",
    "num_lvs = range(2, 11)\n",
    "\n",
    "# select our training dataset\n",
    "# TODO: CHANGE THE FOLLOWING LINES\n",
    "training_dataset = \"Pantano\"\n",
    "X = X_Pantano\n",
    "Y = Y_Pantano\n",
    "\n",
    "test1 = \"Govaere\"\n",
    "test2 = \"Hoang\"\n",
    "\n",
    "X_test1 = X_Govaere\n",
    "X_test2 = X_Hoang\n",
    "Y_test1 = Y_Govaere\n",
    "Y_test2 = Y_Hoang\n",
    "\n",
    "unique, freq = np.unique(Y.iloc[:,0], return_counts=True)\n",
    "print(f\"Unique NAS scores and their corresponding frequency:\\n{[f'{(i,j)}' for i, j in zip(unique, freq)]}\")\n",
    "unique, freq = np.unique(Y.iloc[:,1], return_counts=True)\n",
    "print(f\"Unique Fibrosis scores and their corresponding frequency:\\n{[f'{(i,j)}' for i, j in zip(unique, freq)]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b107c8-062e-4364-8a67-288a219d4256",
   "metadata": {},
   "source": [
    "## Perform cross validation to find ideal number of latent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "56c5c87d-3f8d-4409-85b4-ad4adcffbb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[156], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m Y_test \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39miloc[test_index]\n\u001b[1;32m     15\u001b[0m model \u001b[38;5;241m=\u001b[39m PLSRegression(n_components\u001b[38;5;241m=\u001b[39mlatent_var, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 16\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, Y_train)\n\u001b[1;32m     17\u001b[0m Y_test_hat \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# take the mean in order to be able to generalize the behavior on both phenotypes\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/cross_decomposition/_pls.py:649\u001b[0m, in \u001b[0;36mPLSRegression.fit\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y):\n\u001b[1;32m    632\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit model to data.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \n\u001b[1;32m    634\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;124;03m        Fitted model.\u001b[39;00m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 649\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, Y)\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;66;03m# expose the fitted attributes `x_scores_` and `y_scores_`\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_scores_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_x_scores\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/cross_decomposition/_pls.py:234\u001b[0m, in \u001b[0;36m_PLS.fit\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit model to data.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03m    Fitted model.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    233\u001b[0m check_consistent_length(X, Y)\n\u001b[0;32m--> 234\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m    235\u001b[0m     X, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy, ensure_min_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    236\u001b[0m )\n\u001b[1;32m    237\u001b[0m Y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m    238\u001b[0m     Y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    239\u001b[0m )\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:875\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    869\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    870\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas.DataFrame with sparse columns found.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    871\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt will be converted to a dense numpy array.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    872\u001b[0m         )\n\u001b[1;32m    874\u001b[0m dtypes_orig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtypes)\n\u001b[0;32m--> 875\u001b[0m pandas_requires_conversion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    876\u001b[0m     _pandas_dtype_needs_early_conversion(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dtypes_orig\n\u001b[1;32m    877\u001b[0m )\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(dtype_iter, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m dtype_iter \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[1;32m    879\u001b[0m     dtype_orig \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mresult_type(\u001b[38;5;241m*\u001b[39mdtypes_orig)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:876\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    869\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    870\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas.DataFrame with sparse columns found.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    871\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt will be converted to a dense numpy array.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    872\u001b[0m         )\n\u001b[1;32m    874\u001b[0m dtypes_orig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtypes)\n\u001b[1;32m    875\u001b[0m pandas_requires_conversion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m--> 876\u001b[0m     _pandas_dtype_needs_early_conversion(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dtypes_orig\n\u001b[1;32m    877\u001b[0m )\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(dtype_iter, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m dtype_iter \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[1;32m    879\u001b[0m     dtype_orig \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mresult_type(\u001b[38;5;241m*\u001b[39mdtypes_orig)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:678\u001b[0m, in \u001b[0;36m_pandas_dtype_needs_early_conversion\u001b[0;34m(pd_dtype)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;66;03m# Check these early for pandas versions without extension dtypes\u001b[39;00m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[0;32m--> 678\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    679\u001b[0m     is_bool_dtype,\n\u001b[1;32m    680\u001b[0m     is_float_dtype,\n\u001b[1;32m    681\u001b[0m     is_integer_dtype,\n\u001b[1;32m    682\u001b[0m )\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_bool_dtype(pd_dtype):\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;66;03m# bool and extension booleans need early conversion because __array__\u001b[39;00m\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;66;03m# converts mixed dtype dataframes into object dtypes\u001b[39;00m\n\u001b[1;32m    687\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pearson_coeff_lvs = [] # containing tuples (num_lv, avg pearson coeff)\n",
    "\n",
    "for latent_var in num_lvs:\n",
    "    \n",
    "    pearson_coeff = []\n",
    "\n",
    "    # index into fibrosis column only because we need the correct dim for finding indices, and want to have as equal of splits as possible\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X, Y[Y.columns[1]])):\n",
    "\n",
    "        X_train = X.iloc[train_index]\n",
    "        X_test = X.iloc[test_index]\n",
    "        Y_train = Y.iloc[train_index]\n",
    "        Y_test = Y.iloc[test_index]\n",
    "\n",
    "        model = PLSRegression(n_components=latent_var, scale=False)\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_test_hat = model.predict(X_test)\n",
    "\n",
    "        # take the mean in order to be able to generalize the behavior on both phenotypes\n",
    "        pearson_coeff.append(np.mean(pair_pearsonr(Y_test.values, Y_test_hat)))\n",
    "    \n",
    "    # evaluate the hyperparameter based on the average pearson coeff across all 10 folds\n",
    "    pearson_coeff_lvs.append((latent_var, sum(pearson_coeff)/len(pearson_coeff)))\n",
    "\n",
    "# print the result of the hyperparameter optimization\n",
    "print(f'From 10-fold cross validation on training dataset {training_dataset}, {max(pearson_coeff_lvs, key=lambda x: x[1])[0]} latent variables achieves an average Pearson coeff of {max(pearson_coeff_lvs, key=lambda x: x[1])[1]}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "300ec2bb-7834-4b16-9bba-22e160c31660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Fold 0 saved as models/Pantano_PLSR_fold_0.pkl\n",
      "Model for Fold 1 saved as models/Pantano_PLSR_fold_1.pkl\n",
      "Model for Fold 2 saved as models/Pantano_PLSR_fold_2.pkl\n",
      "Model for Fold 3 saved as models/Pantano_PLSR_fold_3.pkl\n",
      "Model for Fold 4 saved as models/Pantano_PLSR_fold_4.pkl\n",
      "Model for Fold 5 saved as models/Pantano_PLSR_fold_5.pkl\n",
      "Model for Fold 6 saved as models/Pantano_PLSR_fold_6.pkl\n",
      "Model for Fold 7 saved as models/Pantano_PLSR_fold_7.pkl\n",
      "Model for Fold 8 saved as models/Pantano_PLSR_fold_8.pkl\n",
      "Model for Fold 9 saved as models/Pantano_PLSR_fold_9.pkl\n"
     ]
    }
   ],
   "source": [
    "# save the model so we can run it again\n",
    "# this time, store the pearson's coeff for training and validation sets\n",
    "\n",
    "best_lv = max(pearson_coeff_lvs, key=lambda x: x[1])[0]\n",
    "\n",
    "latent_var = best_lv # our best performing hyperparameter\n",
    "train_pearson_coeff = []\n",
    "test_pearson_coeff = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, Y[Y.columns[1]])):\n",
    "    \n",
    "    X_train = X.iloc[train_index]\n",
    "    X_test = X.iloc[test_index]\n",
    "    Y_train = Y.iloc[train_index]\n",
    "    Y_test = Y.iloc[test_index]\n",
    "\n",
    "    model = PLSRegression(n_components=latent_var, scale=False)\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    Y_train_hat = model.predict(X_train) \n",
    "    train_pearson_coeff.append(np.mean(pair_pearsonr(Y_train.values, Y_train_hat)))\n",
    "    \n",
    "    Y_test_hat = model.predict(X_test) \n",
    "    test_pearson_coeff.append(np.mean(pair_pearsonr(Y_test.values, Y_test_hat)))\n",
    "    \n",
    "    filename = f\"models/{training_dataset}_PLSR_fold_{i}.pkl\"\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "    \n",
    "    print(f\"Model for Fold {i} saved as {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1429b4a2-06f3-4060-9df4-da9e5f9cf449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model 0 from models/Pantano_PLSR_fold_0.pkl\n",
      "Loaded model 1 from models/Pantano_PLSR_fold_1.pkl\n",
      "Loaded model 2 from models/Pantano_PLSR_fold_2.pkl\n",
      "Loaded model 3 from models/Pantano_PLSR_fold_3.pkl\n",
      "Loaded model 4 from models/Pantano_PLSR_fold_4.pkl\n",
      "Loaded model 5 from models/Pantano_PLSR_fold_5.pkl\n",
      "Loaded model 6 from models/Pantano_PLSR_fold_6.pkl\n",
      "Loaded model 7 from models/Pantano_PLSR_fold_7.pkl\n",
      "Loaded model 8 from models/Pantano_PLSR_fold_8.pkl\n",
      "Loaded model 9 from models/Pantano_PLSR_fold_9.pkl\n"
     ]
    }
   ],
   "source": [
    "# load all models\n",
    "loaded_models = []\n",
    "for i in range(0, 10):\n",
    "    filename = f\"models/{training_dataset}_PLSR_fold_{i}.pkl\"\n",
    "    with open(filename, 'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "        loaded_models.append(model)\n",
    "    print(f\"Loaded model {i} from {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab44f23-0883-425b-8f62-2f5da31f3144",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Test with the best model on external and shuffled datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4042d78-d6a8-40f3-bc94-2db805573a8b",
   "metadata": {},
   "source": [
    "## Trying to recreate the all_coeff dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a3d70d",
   "metadata": {},
   "source": [
    "# Hide the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79dfc81e-850f-4278-b08e-50faaf17b48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the model to create the total predicted scores\n",
    "# run on the other two external test sets and the shuffled training dataset\n",
    "# TODO: CHANGE THE FOLLOWING 6 LINES\n",
    "X_test1 = X_Hoang\n",
    "X_test2 = X_Pantano\n",
    "Y_test1 = Y_Hoang\n",
    "Y_test2 = Y_Pantano\n",
    "test1 = \"Hoang\"\n",
    "test2 = \"Pantano\"\n",
    "\n",
    "train_pearson_coeff = []\n",
    "validation_pearson_coeff = []\n",
    "test1_pearson_coeff = []\n",
    "test2_pearson_coeff = []\n",
    "shuffled_pearson_coeff = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, Y[Y.columns[1]])):\n",
    "\n",
    "    X_train = X.iloc[train_index]\n",
    "    X_val = X.iloc[test_index]\n",
    "    Y_train = Y.iloc[train_index]\n",
    "    Y_val = Y.iloc[test_index]\n",
    "\n",
    "    # model = loaded_models[i]\n",
    "    model = PLSRegression(n_components=latent_var, scale=False)\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    Y_train_hat = model.predict(X_train)\n",
    "    train_pearson_coeff.append(np.mean(pair_pearsonr(Y_train.values, Y_train_hat)))\n",
    "    \n",
    "    Y_val_hat = model.predict(X_val)\n",
    "    validation_pearson_coeff.append(np.mean(pair_pearsonr(Y_val.values, Y_val_hat)))\n",
    "    \n",
    "    Y_pred = model.predict(X_test1)\n",
    "    test1_pearson_coeff.append(np.mean(pair_pearsonr(Y_test1.values, Y_pred)))\n",
    "\n",
    "    Y_pred = model.predict(X_test2)\n",
    "    test2_pearson_coeff.append(np.mean(pair_pearsonr(Y_test2.values, Y_pred)))\n",
    "\n",
    "    Y_pred = model.predict(X_shuffled)\n",
    "    shuffled_pearson_coeff.append(np.mean(pair_pearsonr(Y.values, Y_pred)))\n",
    "\n",
    "    model = PLSRegression(n_components=latent_var, scale=False)\n",
    "    model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cbf711",
   "metadata": {},
   "source": [
    "# Show the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1ce0ca3d-71f6-4a4b-b3ad-b1bdc919a125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 0\n",
      "Evaluating fold 1\n",
      "Evaluating fold 2\n",
      "Evaluating fold 3\n",
      "Evaluating fold 4\n",
      "Evaluating fold 5\n",
      "Evaluating fold 6\n",
      "Evaluating fold 7\n",
      "Evaluating fold 8\n",
      "Evaluating fold 9\n"
     ]
    }
   ],
   "source": [
    "# creating a better all_coeff dataframe\n",
    "# TODO: CHANGE THE FOLLOWING 6 LINES\n",
    "# test1 = \"Govaere\"\n",
    "# test2 = \"Pantano\"\n",
    "\n",
    "# X_test1 = X_Govaere\n",
    "# X_test2 = X_Pantano\n",
    "# Y_test1 = Y_Govaere\n",
    "# Y_test2 = Y_Pantano\n",
    "X_shuffled = X.apply(lambda col: np.random.permutation(col.values), axis=0)\n",
    "X_shuffled.index = X.index # ensure the gene names are maintained\n",
    "\n",
    "results = [] # initialize list of all results\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, Y[Y.columns[1]])):\n",
    "\n",
    "    # split data\n",
    "    X_train = X.iloc[train_index]\n",
    "    X_val = X.iloc[test_index]\n",
    "    Y_train = Y.iloc[train_index]\n",
    "    Y_val = Y.iloc[test_index]\n",
    "\n",
    "    partitions = [[X_train, X_val, X_test1, X_test2, X_shuffled], [Y_train, Y_val, Y_test1, Y_test2, Y], [\"Train\", \"Validation\", test1, test2, \"Shuffled\"]]\n",
    "\n",
    "    print(f'Evaluating fold {i}')\n",
    "    model = loaded_models[i]\n",
    "\n",
    "    for j in range(len(partitions[0])):\n",
    "        \n",
    "        Y_hat = model.predict(partitions[0][j])\n",
    "        corr_nas, _ = pearsonr(partitions[1][j].values[:,0], Y_hat[:,0]) # NAS correlation\n",
    "        corr_fib, _ = pearsonr(partitions[1][j].values[:,1], Y_hat[:,1]) # fibrosis correlation\n",
    "        corr_mean = np.mean(pair_pearsonr(partitions[1][j].values, Y_hat)) # mean correlation\n",
    "        \n",
    "        results.append({\n",
    "            \"TuningDataset\": training_dataset,\n",
    "            \"Fold\": f\"Fold{i+1}\",\n",
    "            \"Partition\": partitions[2][j],\n",
    "            \"Phenotype\": \"Fibrosis\", \n",
    "            \"Pearson_Coefficient\": corr_fib\n",
    "        })\n",
    "        results.append({\n",
    "            \"TuningDataset\": training_dataset,\n",
    "            \"Fold\": f\"Fold{i+1}\",\n",
    "            \"Partition\": partitions[2][j],\n",
    "            \"Phenotype\": \"NAS\",\n",
    "            \"Pearson_Coefficient\": corr_nas\n",
    "        })\n",
    "        results.append({\n",
    "            \"TuningDataset\": training_dataset,\n",
    "            \"Fold\": f\"Fold{i+1}\",\n",
    "            \"Partition\": partitions[2][j],\n",
    "            \"Phenotype\": \"Combined\",\n",
    "            \"Pearson_Coefficient\": corr_mean\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ac305a9b-f9fb-4002-a505-c3e31223e395",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.DataFrame(results)\n",
    "# results_df[(results_df[\"Phenotype\"] == \"NAS\") & (results_df[\"Partition\"] == \"Pantano\")]\n",
    "# results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "cc9de344",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat([g, h, p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "00cf3b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "test.to_csv(\"datasets/PLSR_pearson_coefficients.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e73208-ec0a-4bdb-947a-deb511776ec4",
   "metadata": {},
   "source": [
    "## Plot with Mann-Whitney test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "29f94ac7-553a-4e11-83dd-f988fd188bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "significant_combinations = []\n",
    "\n",
    "combinations = [(x, 4) for x in [1, 2, 3]]\n",
    "for combo in combinations:\n",
    "    data1 = all_pearsons_coeff.iloc[:,combo[0]]\n",
    "    data2 = all_pearsons_coeff.iloc[:,combo[1]]\n",
    "    \n",
    "    # calculate significance\n",
    "    U, p = stats.mannwhitneyu(data1, data2, alternative='two-sided')\n",
    "    if p < 0.05:\n",
    "        significant_combinations.append([combo, p])\n",
    "\n",
    "# create a set of axes\n",
    "ax = plt.axes()\n",
    "# create a boxplot on the axes\n",
    "bp = ax.boxplot(all_pearsons_coeff, patch_artist=True)\n",
    "# graph title\n",
    "ax.set_title(f\"Tuning PLSR Model with {training_dataset} in-vivo Training Data\", fontsize=16)\n",
    "# label y-axis\n",
    "ax.set_ylabel(\"Pearson Coefficient\")\n",
    "\n",
    "xticklabels = all_pearsons_coeff.columns.tolist()\n",
    "ax.set_xticklabels(xticklabels)\n",
    "\n",
    "# Change the colour of the boxes to Seaborn's 'pastel' palette\n",
    "colors = sns.color_palette('colorblind')\n",
    "for patch, color in zip(bp['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "# Colour of the median lines\n",
    "plt.setp(bp['medians'], color='k')\n",
    "\n",
    "# Get the y-axis limits\n",
    "bottom, top = ax.get_ylim()\n",
    "y_range = top - bottom\n",
    "\n",
    "# Significance bars\n",
    "for i, significant_combination in enumerate(significant_combinations):\n",
    "    # Columns corresponding to the datasets of interest\n",
    "    # add one because the df indexing is 0 indexed, but plot is 1 indexed\n",
    "    x1 = significant_combination[0][0] + 1 \n",
    "    x2 = significant_combination[0][1] + 1\n",
    "    # What level is this bar among the bars above the plot?\n",
    "    level = len(significant_combinations) - i\n",
    "    # Plot the bar\n",
    "    bar_height = (y_range * 0.07 * level) + top\n",
    "    bar_tips = bar_height - (y_range * 0.02)\n",
    "    plt.plot(\n",
    "        [x1, x1, x2, x2],\n",
    "        [bar_tips, bar_height, bar_height, bar_tips], lw=1, c='k'\n",
    "    )\n",
    "    # Significance level\n",
    "    p = significant_combination[1]\n",
    "    if p < 0.001:\n",
    "        sig_symbol = '***'\n",
    "    elif p < 0.01:\n",
    "        sig_symbol = '**'\n",
    "    elif p < 0.05:\n",
    "        sig_symbol = '*'\n",
    "    text_height = bar_height + (y_range * 0.01)\n",
    "    plt.text((x1 + x2) * 0.5, text_height, sig_symbol, ha='center', va='bottom', c='k')\n",
    "\n",
    "plt.savefig(f'graphs/PLSR_tuning_with_{training_dataset}.png', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "84199023-0ebd-4c67-b2e2-8b8b81b66e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(1, 4), 0.00018267179110955002],\n",
       " [(2, 4), 0.00018267179110955002],\n",
       " [(3, 4), 0.00018267179110955002]]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "significant_combinations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
